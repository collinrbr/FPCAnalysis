{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "782d2bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import FPCAnalysis\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9e533fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load everything we need\n",
    "#-----------------------\n",
    "\n",
    "path = '/home/crbrown/M06_th45/'\n",
    "numframe = 2000\n",
    "inputs = FPCAnalysis.ddhr.read_input(path=path)\n",
    "\n",
    "#load the fields data\n",
    "dfields = FPCAnalysis.ddhr.field_loader(path=path,num=numframe)\n",
    "dfields.keys()\n",
    "\n",
    "#load the density data\n",
    "dden = FPCAnalysis.ddhr.den_loader(path=path,num=numframe)\n",
    "dden.keys()\n",
    "\n",
    "#load subset of particles that we want to compute the FPC of\n",
    "path_particles = path+\"Output/Raw/Sp01/raw_sp01_{:08d}.h5\" #note that this specifies the species!\n",
    "x1 = 39.5\n",
    "x2 = 41.5\n",
    "y1 = 0\n",
    "y2 = .5 #note, for the example data, yz plane is 12x12 d_i large, but here we load just part of that for computational efficiency while learning\n",
    "z1 = 0\n",
    "z2 = .5\n",
    "dparticles = FPCAnalysis.ddhr.read_box_of_particles(path_particles, numframe, x1, x2, y1, y2, z1, z2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c58e9238",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note, this analysis is performed in the simulation rest frame!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37d3d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute dfluc\n",
    "# At the core of our shock analysis is the idea that we can separate the fields into fluctuating and steady state fields\n",
    "\n",
    "dfluc = FPCAnalysis.anl.remove_average_fields_over_yz(dfields)\n",
    "dfavg = FPCAnalysis.anl.get_average_fields_over_yz(dfields)\n",
    "\n",
    "testkey = 'ex'\n",
    "testidxx = 12\n",
    "testidyy = 5\n",
    "testidzz = 35\n",
    "\n",
    "#these should be equal\n",
    "dfluc[testkey][testidzz,testidyy,testidxx]+dfavg[testkey][testidzz,testidyy,testidxx],dfields[testkey][testidzz,testidyy,testidxx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be5a88d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For example, E_x = \\overline{E_x} + \\widetilde{E_x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb7d32fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#we typically work with the electric fields, \n",
    "#  but it's easier to understand if we look at the compressible component of the magnetic field\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(dfields['ex_xx'],dfields['bz'][0,0,:],label=r'$B_z(z_0,y_0,x)$')\n",
    "plt.plot(dfields['ex_xx'],dfluc['bz'][0,0,:],label=r'$\\widetilde{B_z}(z_0,y_0,x)$')\n",
    "plt.plot(dfields['ex_xx'],dfavg['bz'][0,0,:],label=r'$\\overline{B_z}(z_0,y_0,x)$')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f187e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do the wavelet transform of the fluctuating fields\n",
    "#--------------------------------------------------\n",
    "\n",
    "lowerresolution = True #lower field resolution for speed!\n",
    "if(lowerresolution):\n",
    "    print('dfields[\"ex\"].shape before:',dfields['ex'].shape)\n",
    "    dfields = FPCAnalysis.ao.avg_dict(dfields,binidxsz=[2,2,2]) #note, each element in binidxsz must be an integer divisor of the shape of its respective axis\n",
    "    dfluc = FPCAnalysis.ao.avg_dict(dfluc,binidxsz=[2,2,2])\n",
    "    dfavg = FPCAnalysis.ao.avg_dict(dfavg,binidxsz=[2,2,2])\n",
    "    print('dfields[\"ex\"].shape after:',dfields['ex'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13102343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computes ex(kz,ky,kz;xx)\n",
    "kz, ky, kx, exkzkykxxx = FPCAnalysis.anl.transform_field_to_kzkykxxx(dfields,'ex')\n",
    "xx = dfields['ex_xx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73e25ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kz.shape,ky.shape,kx.shape,xx.shape,exkzkykxxx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "462c6edb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kzidx = 0\n",
    "kyidx = 0\n",
    "\n",
    "print('kz,ky of this plot is ',kz[kzidx],ky[kyidx])\n",
    "\n",
    "#vars that make model shock on bottom panel\n",
    "Bz2_over_Bz1 = 3.8 #approx compression ratio\n",
    "xpos_shock = 38.625 #position of jump of model shock\n",
    "xpos_line = 39.875 #vertical black line\n",
    "\n",
    "fieldvals = dfavg['bz'][0,0,:]\n",
    "\n",
    "flnm = ''\n",
    "FPCAnalysis.pltfr.plot_wlt_over_field(xx, kx, exkzkykxxx[kzidx,kyidx,::], fieldvals, flnm = flnm, ylim = [0,5],\n",
    "               Bz2_over_Bz1 = Bz2_over_Bz1, xpos_shock = xpos_shock, xpos_line = xpos_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d115f300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
